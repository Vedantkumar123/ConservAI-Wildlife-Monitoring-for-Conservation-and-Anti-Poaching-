{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkXHdJidlpPs",
        "outputId": "d043af80-eaeb-4194-cb69-c5968a4ed368"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics -q\n",
        "!pip install roboflow -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v9yvh89MdBS",
        "outputId": "22598810-5b29-45e0-ddb4-4d7251a6ed66"
      },
      "outputs": [],
      "source": [
        "from ultralytics.nn.modules import (\n",
        "    AIFI,\n",
        "    C1,\n",
        "    C2,\n",
        "    C2PSA,\n",
        "    C3,\n",
        "    C3TR,\n",
        "    ELAN1,\n",
        "    OBB,\n",
        "    PSA,\n",
        "    SPP,\n",
        "    SPPELAN,\n",
        "    SPPF,\n",
        "    A2C2f,\n",
        "    AConv,\n",
        "    ADown,\n",
        "    Bottleneck,\n",
        "    BottleneckCSP,\n",
        "    C2f,\n",
        "    C2fAttn,\n",
        "    C2fCIB,\n",
        "    C2fPSA,\n",
        "    C3Ghost,\n",
        "    C3k2,\n",
        "    C3x,\n",
        "    CBFuse,\n",
        "    CBLinear,\n",
        "    Classify,\n",
        "    Concat,\n",
        "    Conv,\n",
        "    Conv2,\n",
        "    ConvTranspose,\n",
        "    Detect,\n",
        "    DWConv,\n",
        "    DWConvTranspose2d,\n",
        "    Focus,\n",
        "    GhostBottleneck,\n",
        "    GhostConv,\n",
        "    HGBlock,\n",
        "    HGStem,\n",
        "    ImagePoolingAttn,\n",
        "    Index,\n",
        "    LRPCHead,\n",
        "    Pose,\n",
        "    RepC3,\n",
        "    RepConv,\n",
        "    RepNCSPELAN4,\n",
        "    RepVGGDW,\n",
        "    ResNetLayer,\n",
        "    RTDETRDecoder,\n",
        "    SCDown,\n",
        "    Segment,\n",
        "    TorchVision,\n",
        "    WorldDetect,\n",
        "    YOLOEDetect,\n",
        "    YOLOESegment,\n",
        "    v10Detect,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['../../myconfig.config']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import configparser\n",
        "config = configparser.ConfigParser()\n",
        "config.read('../../myconfig.config')\n",
        "print(config['roboflow']['roboflow_api_key'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQwNxIhP_EFx",
        "outputId": "1996b950-7332-4dbd-f06b-cd3ef52fa68f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in ../../Dataset/Test_dataset to yolov11:: 100%|██████████| 44579/44579 [00:40<00:00, 1101.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to ../../Dataset/Test_dataset in yolov11:: 100%|██████████| 1396/1396 [00:01<00:00, 928.36it/s] \n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key='u8Ur5ywKLswqwt0uMTXl')\n",
        "project = rf.workspace(\"poacher-ifyuf\").project(\"poacher\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov11\", location=\"../../Dataset/Test_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bOcaZ6dnMDR"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/drive/MyDrive/Colab_Notebooks/YOLO_architecture/utillity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "go1t4uz6uARV"
      },
      "outputs": [],
      "source": [
        "from ultralytics import nn\n",
        "from ultralytics.nn import modules, tasks\n",
        "import ultralytics.nn.autobackend as autobackend\n",
        "from model_classes import Upsample, C2f, SPPF, DFL, Head, Bottleneck, Concat\n",
        "from model_classes_v11 import C3k2, C2PSA, Conv, Attention, PSABlock, C3k, Bottleneck, C2f\n",
        "from ultralytics.nn.tasks import parse_model, yaml_model_load\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "def patch_ultralytics_layers(custom_classes):\n",
        "    submodules = [\n",
        "        nn,                          # ultralytics.nn\n",
        "        modules,                     # ultralytics.nn.modules\n",
        "        tasks,                       # ultralytics.nn.tasks\n",
        "        autobackend,                 # ultralytics.nn.autobackend\n",
        "    ]\n",
        "\n",
        "    for cls in custom_classes:\n",
        "        for mod in submodules:\n",
        "            mod.__dict__[cls.__name__] = cls\n",
        "\n",
        "def build_model(model_yaml, version='n', ch=3, verbose=False, custom_classes=[]):\n",
        "\n",
        "  patch_ultralytics_layers(custom_classes)\n",
        "\n",
        "  mod_ya = model_yaml if isinstance(model_yaml, dict) else yaml_model_load(model_yaml)\n",
        "  mod_ya['scale'] = version.lower()\n",
        "  model, save  = parse_model(deepcopy(mod_ya), ch=ch, verbose=verbose)\n",
        "\n",
        "  return model,save\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg1Fe3WHzfZJ",
        "outputId": "d9ddbd32-916b-4438-c8ff-ee7337ac837d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  model_classes_v11.Conv                       [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  model_classes_v11.Conv                       [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  model_classes_v11.C3k2                       [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  model_classes_v11.Conv                       [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  model_classes_v11.C3k2                       [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  model_classes_v11.Conv                       [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  model_classes_v11.C3k2                       [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  model_classes_v11.Conv                       [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  model_classes_v11.C3k2                       [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  model_classes.SPPF                           [512, 512, 5]                 \n",
            " 10                  -1  1    990976  model_classes_v11.C2PSA                      [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  model_classes.Concat                         [1]                           \n",
            " 13                  -1  1    443776  model_classes_v11.C3k2                       [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  model_classes.Concat                         [1]                           \n",
            " 16                  -1  1    127680  model_classes_v11.C3k2                       [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  model_classes_v11.Conv                       [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  model_classes.Concat                         [1]                           \n",
            " 19                  -1  1    345472  model_classes_v11.C3k2                       [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  model_classes_v11.Conv                       [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  model_classes.Concat                         [1]                           \n",
            " 22                  -1  1   1511424  model_classes_v11.C3k2                       [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1    850368  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
            "my_YOLOv11s summary: 184 layers, 9,458,752 parameters, 9,458,736 gradients, 21.7 GFLOPs\n",
            "\n",
            "9.46 million parameters\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "m_class = [Upsample, Conv, C2f, SPPF, DFL, Head, Bottleneck, Concat, C3k2, C2PSA, Attention, PSABlock, C3k, Bottleneck, C2f]\n",
        "model_yaml = \"my_yolov11s.yaml\"\n",
        "\n",
        "model_save = build_model(model_yaml, custom_classes=m_class, version='l', verbose=False)\n",
        "\n",
        "model = YOLO(model_yaml, verbose=True)\n",
        "print(f\"{sum(p.numel() for p in model.parameters()) / 1e6:.2f} million parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1    850368  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
            "YOLO11s summary: 181 layers, 9,458,752 parameters, 9,458,736 gradients, 21.7 GFLOPs\n",
            "\n",
            "9.46 million parameters\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv11l model\n",
        "model = YOLO(\"yolo11s.yaml\",verbose=True)  # Replace with the path to your model file\n",
        "print(f\"{sum(p.numel() for p in model.parameters()) / 1e6:.2f} million parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSsalGpq-_ly",
        "outputId": "63d0b951-9c16-46b6-91dc-1f563421d2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.202 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.173  Python-3.11.3 torch-2.7.1+cpu CPU (Intel Core(TM) i5-8250U 1.60GHz)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Project_1\\Dataset\\Test_dataset\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=64, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=my_yolov11s.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Ultralytics_work\\ultralytics\\runs\\detect\\train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=22\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  model_classes_v11.Conv                       [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  model_classes_v11.Conv                       [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  model_classes_v11.C3k2                       [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  model_classes_v11.Conv                       [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  model_classes_v11.C3k2                       [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  model_classes_v11.Conv                       [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  model_classes_v11.C3k2                       [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  model_classes_v11.Conv                       [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  model_classes_v11.C3k2                       [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  model_classes.SPPF                           [512, 512, 5]                 \n",
            " 10                  -1  1    990976  model_classes_v11.C2PSA                      [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  model_classes.Concat                         [1]                           \n",
            " 13                  -1  1    443776  model_classes_v11.C3k2                       [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  model_classes.Concat                         [1]                           \n",
            " 16                  -1  1    127680  model_classes_v11.C3k2                       [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  model_classes_v11.Conv                       [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  model_classes.Concat                         [1]                           \n",
            " 19                  -1  1    345472  model_classes_v11.C3k2                       [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  model_classes_v11.Conv                       [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  model_classes.Concat                         [1]                           \n",
            " 22                  -1  1   1511424  model_classes_v11.C3k2                       [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1    827922  ultralytics.nn.modules.head.Detect           [22, [128, 256, 512]]         \n",
            "my_YOLOv11s summary: 184 layers, 9,436,306 parameters, 9,436,290 gradients, 21.6 GFLOPs\n",
            "\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 6.21.5 MB/s, size: 70.6 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Project_1\\Dataset\\Test_dataset\\train\\labels... 604 images, 9 backgrounds, 0 corrupt: 100%|██████████| 604/604 [00:02<00:00, 253.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Project_1\\Dataset\\Test_dataset\\train\\labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.40.1 ms, read: 6.01.4 MB/s, size: 56.0 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Project_1\\Dataset\\Test_dataset\\valid\\labels... 58 images, 1 backgrounds, 0 corrupt: 100%|██████████| 58/58 [00:00<00:00, 240.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Project_1\\Dataset\\Test_dataset\\valid\\labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "c:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Ultralytics_work\\ultralytics\\runs\\detect\\train\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 64 train, 64 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Ultralytics_work\\ultralytics\\runs\\detect\\train\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/1         0G      6.586      5.247      4.233         38         64: 100%|██████████| 38/38 [00:26<00:00,  1.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         58        122          0          0          0          0\n",
            "\n",
            "1 epochs completed in 0.009 hours.\n",
            "Optimizer stripped from C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Ultralytics_work\\ultralytics\\runs\\detect\\train\\weights\\last.pt, 19.1MB\n",
            "Optimizer stripped from C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Ultralytics_work\\ultralytics\\runs\\detect\\train\\weights\\best.pt, 19.1MB\n",
            "\n",
            "Validating C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Ultralytics_work\\ultralytics\\runs\\detect\\train\\weights\\best.pt...\n",
            "Ultralytics 8.3.173  Python-3.11.3 torch-2.7.1+cpu CPU (Intel Core(TM) i5-8250U 1.60GHz)\n",
            "my_YOLOv11s summary: 117 layers, 9,423,234 parameters, 0 gradients, 21.4 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         58        122          0          0          0          0\n",
            "                animal          2          2          0          0          0          0\n",
            "                  bull          1          1          0          0          0          0\n",
            "                 camel          2          4          0          0          0          0\n",
            "                  deer          3          3          0          0          0          0\n",
            "                   dog          2          3          0          0          0          0\n",
            "              elephant          8          8          0          0          0          0\n",
            "                   fox          1          1          0          0          0          0\n",
            "                  lion          2          2          0          0          0          0\n",
            "               poacher         18         29          0          0          0          0\n",
            "                ranger         18         32          0          0          0          0\n",
            "                 rhino          5          6          0          0          0          0\n",
            "                 tiger          1          1          0          0          0          0\n",
            "                weapon         24         30          0          0          0          0\n",
            "Speed: 0.0ms preprocess, 12.5ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
            "Results saved to \u001b[1mC:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Ultralytics_work\\ultralytics\\runs\\detect\\train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "results = model.train(data=r\"C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Project_1\\Dataset\\Test_dataset\\data.yaml\", epochs=1, imgsz=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FNwBXzbqE-m3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
