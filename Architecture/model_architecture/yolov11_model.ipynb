{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkXHdJidlpPs",
        "outputId": "d043af80-eaeb-4194-cb69-c5968a4ed368"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics -q\n",
        "!pip install roboflow -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v9yvh89MdBS",
        "outputId": "22598810-5b29-45e0-ddb4-4d7251a6ed66"
      },
      "outputs": [],
      "source": [
        "from ultralytics.nn.modules import (\n",
        "    AIFI,\n",
        "    C1,\n",
        "    C2,\n",
        "    C2PSA,\n",
        "    C3,\n",
        "    C3TR,\n",
        "    ELAN1,\n",
        "    OBB,\n",
        "    PSA,\n",
        "    SPP,\n",
        "    SPPELAN,\n",
        "    SPPF,\n",
        "    A2C2f,\n",
        "    AConv,\n",
        "    ADown,\n",
        "    Bottleneck,\n",
        "    BottleneckCSP,\n",
        "    C2f,\n",
        "    C2fAttn,\n",
        "    C2fCIB,\n",
        "    C2fPSA,\n",
        "    C3Ghost,\n",
        "    C3k2,\n",
        "    C3x,\n",
        "    CBFuse,\n",
        "    CBLinear,\n",
        "    Classify,\n",
        "    Concat,\n",
        "    Conv,\n",
        "    Conv2,\n",
        "    ConvTranspose,\n",
        "    Detect,\n",
        "    DWConv,\n",
        "    DWConvTranspose2d,\n",
        "    Focus,\n",
        "    GhostBottleneck,\n",
        "    GhostConv,\n",
        "    HGBlock,\n",
        "    HGStem,\n",
        "    ImagePoolingAttn,\n",
        "    Index,\n",
        "    LRPCHead,\n",
        "    Pose,\n",
        "    RepC3,\n",
        "    RepConv,\n",
        "    RepNCSPELAN4,\n",
        "    RepVGGDW,\n",
        "    ResNetLayer,\n",
        "    RTDETRDecoder,\n",
        "    SCDown,\n",
        "    Segment,\n",
        "    TorchVision,\n",
        "    WorldDetect,\n",
        "    YOLOEDetect,\n",
        "    YOLOESegment,\n",
        "    v10Detect,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import configparser\n",
        "config = configparser.ConfigParser()\n",
        "config.read('../../myconfig.config')\n",
        "print(config['roboflow']['roboflow_api_key'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQwNxIhP_EFx",
        "outputId": "1996b950-7332-4dbd-f06b-cd3ef52fa68f"
      },
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key='u8Ur5ywKLswqwt0uMTXl')\n",
        "project = rf.workspace(\"poacher-ifyuf\").project(\"poacher\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov11\", location=\"../../Dataset/Test_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bOcaZ6dnMDR"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/drive/MyDrive/Colab_Notebooks/YOLO_architecture/utillity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "go1t4uz6uARV"
      },
      "outputs": [],
      "source": [
        "from ultralytics import nn\n",
        "from ultralytics.nn import modules, tasks\n",
        "import ultralytics.nn.autobackend as autobackend\n",
        "from model_classes import Upsample, C2f, SPPF, DFL, Head, Bottleneck, Concat\n",
        "from model_classes_v11 import C3k2, C2PSA, Conv, Attention, PSABlock, C3k, Bottleneck, C2f\n",
        "from model_classes_v11_modified import CBAM, ASPP_Lite, MobileViTBlock, ConvBNAct, Channel_Attention, Spatial_Attention\n",
        "from ultralytics.nn.tasks import yaml_model_load\n",
        "from copy import deepcopy\n",
        "import sys\n",
        "import ultralytics.nn.tasks as tasks\n",
        "import my_tasks\n",
        "from my_tasks import my_parse_model\n",
        "\n",
        "\n",
        "def change_parse_model():\n",
        "    # Replace in the tasks module itself\n",
        "    tasks.parse_model = my_parse_model\n",
        "    # Replace in sys.modules so any \"from ultralytics.nn.tasks import parse_model\"\n",
        "    # will now point to yours\n",
        "    sys.modules['ultralytics.nn.tasks'].parse_model = my_parse_model\n",
        "    return my_parse_model\n",
        "\n",
        "def patch_ultralytics_layers(custom_classes):\n",
        "    submodules = [\n",
        "        nn,                          # ultralytics.nn\n",
        "        modules,                     # ultralytics.nn.modules\n",
        "        tasks,                       # ultralytics.nn.tasks\n",
        "        autobackend,                 # ultralytics.nn.autobackend\n",
        "        my_tasks\n",
        "    ]\n",
        "\n",
        "    for cls in custom_classes:\n",
        "        for mod in submodules:\n",
        "            mod.__dict__[cls.__name__] = cls\n",
        "\n",
        "def build_model(model_yaml, version='n', ch=3, verbose=False, custom_classes=[]):\n",
        "  parse_model = change_parse_model()\n",
        "  patch_ultralytics_layers(custom_classes)\n",
        "  mod_ya = model_yaml if isinstance(model_yaml, dict) else yaml_model_load(model_yaml)\n",
        "  mod_ya['scale'] = version.lower()\n",
        "  model, save  = parse_model(deepcopy(mod_ya), ch=ch, verbose=verbose)\n",
        "\n",
        "  return model,save\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg1Fe3WHzfZJ",
        "outputId": "d9ddbd32-916b-4438-c8ff-ee7337ac837d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  model_classes_v11.Conv                       [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  model_classes_v11.Conv                       [64, 128, 3, 2]               \n",
            "  2                  -1  2    173824  model_classes_v11.C3k2                       [128, 256, 2, True, 0.25]     \n",
            "  3                  -1  1     65890  model_classes_v11_modified.CBAM              [256]                         \n",
            "  4                  -1  1    590336  model_classes_v11.Conv                       [256, 256, 3, 2]              \n",
            "  5                  -1  2    691712  model_classes_v11.C3k2                       [256, 512, 2, True, 0.25]     \n",
            "  6                  -1  1   3380736  model_classes_v11_modified.MobileViTBlock    [512, 2]                      \n",
            "  7                  -1  1   2360320  model_classes_v11.Conv                       [512, 512, 3, 2]              \n",
            "  8                  -1  2   2234368  model_classes_v11.C3k2                       [512, 512, 2, True]           \n",
            "  9                  -1  1   2360320  model_classes_v11.Conv                       [512, 512, 3, 2]              \n",
            " 10                  -1  2   2234368  model_classes_v11.C3k2                       [512, 512, 2, True]           \n",
            " 11                  -1  1    656896  model_classes.SPPF                           [512, 512, 5]                 \n",
            " 12                  -1  1   2885888  model_classes_v11_modified.ASPP_Lite         [512]                         \n",
            " 13                  -1  2   1455616  model_classes_v11.C2PSA                      [512, 512, 2]                 \n",
            " 14                  -1  1    262754  model_classes_v11_modified.CBAM              [512]                         \n",
            " 15                  -1  1         0  model_classes.Upsample                       [2, 'nearest']                \n",
            " 16             [-1, 8]  1         0  model_classes.Concat                         [1]                           \n",
            " 17                  -1  2   2496512  model_classes_v11.C3k2                       [1024, 512, 2, True]          \n",
            " 18                  -1  1         0  model_classes.Upsample                       [2, 'nearest']                \n",
            " 19             [-1, 6]  1         0  model_classes.Concat                         [1]                           \n",
            " 20                  -1  2    756736  model_classes_v11.C3k2                       [1024, 256, 2, True]          \n",
            " 21                  -1  1    590336  model_classes_v11.Conv                       [256, 256, 3, 2]              \n",
            " 22            [-1, 15]  1         0  model_classes.Concat                         [1]                           \n",
            " 23                  -1  2   2365440  model_classes_v11.C3k2                       [768, 512, 2, True]           \n",
            " 24                  -1  1   2360320  model_classes_v11.Conv                       [512, 512, 3, 2]              \n",
            " 25            [-1, 12]  1         0  model_classes.Concat                         [1]                           \n",
            " 26                  -1  2   2496512  model_classes_v11.C3k2                       [1024, 512, 2, True]          \n",
            " 27        [16, 19, 22]  1  14662336  ultralytics.nn.modules.head.Detect           [80, [1024, 1024, 768]]       \n",
            "my_YOLOv11l_back_modified summary: 422 layers, 45,157,060 parameters, 45,157,044 gradients, 220.6 GFLOPs\n",
            "\n",
            "45.16 million parameters\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "m_class = [Upsample, Conv, C2f, SPPF, DFL, Head, Bottleneck, Concat, C3k2, C2PSA, Attention, PSABlock, C3k, Bottleneck, C2f]\n",
        "m_modified = [CBAM, ASPP_Lite, MobileViTBlock, ConvBNAct, Channel_Attention, Spatial_Attention]\n",
        "m_class.extend(m_modified)\n",
        "model_yaml = \"my_yolov11l_back_modified.yaml\"\n",
        "\n",
        "model_save = build_model(model_yaml, custom_classes=m_class, version='l', verbose=False)\n",
        "\n",
        "model = YOLO(model_yaml, verbose=True)\n",
        "print(f\"{sum(p.numel() for p in model.parameters()) / 1e6:.2f} million parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  model_classes_v11.Conv                       [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  model_classes_v11.Conv                       [64, 128, 3, 2]               \n",
            "  2                  -1  2    173824  model_classes_v11.C3k2                       [128, 256, 2, True, 0.25]     \n",
            "  3                  -1  1    590336  model_classes_v11.Conv                       [256, 256, 3, 2]              \n",
            "  4                  -1  2    691712  model_classes_v11.C3k2                       [256, 512, 2, True, 0.25]     \n",
            "  5                  -1  1   2360320  model_classes_v11.Conv                       [512, 512, 3, 2]              \n",
            "  6                  -1  2   2234368  model_classes_v11.C3k2                       [512, 512, 2, True]           \n",
            "  7                  -1  1   2360320  model_classes_v11.Conv                       [512, 512, 3, 2]              \n",
            "  8                  -1  2   2234368  model_classes_v11.C3k2                       [512, 512, 2, True]           \n",
            "  9                  -1  1    656896  model_classes.SPPF                           [512, 512, 5]                 \n",
            " 10                  -1  2   1455616  model_classes_v11.C2PSA                      [512, 512, 2]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  model_classes.Concat                         [1]                           \n",
            " 13                  -1  2   2496512  model_classes_v11.C3k2                       [1024, 512, 2, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  model_classes.Concat                         [1]                           \n",
            " 16                  -1  2    756736  model_classes_v11.C3k2                       [1024, 256, 2, True]          \n",
            " 17                  -1  1    590336  model_classes_v11.Conv                       [256, 256, 3, 2]              \n",
            " 18            [-1, 13]  1         0  model_classes.Concat                         [1]                           \n",
            " 19                  -1  2   2365440  model_classes_v11.C3k2                       [768, 512, 2, True]           \n",
            " 20                  -1  1   2360320  model_classes_v11.Conv                       [512, 512, 3, 2]              \n",
            " 21            [-1, 10]  1         0  model_classes.Concat                         [1]                           \n",
            " 22                  -1  2   2496512  model_classes_v11.C3k2                       [1024, 512, 2, True]          \n",
            " 23        [16, 19, 22]  1   1472704  ultralytics.nn.modules.head.Detect           [80, [256, 512, 512]]         \n",
            "YOLO11l summary: 360 layers, 25,372,160 parameters, 25,372,144 gradients, 87.6 GFLOPs\n",
            "\n",
            "25.37 million parameters\n"
          ]
        }
      ],
      "source": [
        "# from ultralytics import YOLO\n",
        "\n",
        "# # Load the YOLOv11l model\n",
        "# model = YOLO(\"yolo11l.yaml\",verbose=True)  # Replace with the path to your model file\n",
        "# print(f\"{sum(p.numel() for p in model.parameters()) / 1e6:.2f} million parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSsalGpq-_ly",
        "outputId": "63d0b951-9c16-46b6-91dc-1f563421d2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.203 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.173  Python-3.11.3 torch-2.7.1+cpu CPU (Intel Core(TM) i5-8250U 1.60GHz)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Project_1\\Dataset\\Test_dataset\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=64, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=my_yolov11l_back_modified.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Ultralytics_work\\ultralytics\\runs\\detect\\train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=22\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  model_classes_v11.Conv                       [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  model_classes_v11.Conv                       [64, 128, 3, 2]               \n",
            "  2                  -1  2    173824  model_classes_v11.C3k2                       [128, 256, 2, True, 0.25]     \n",
            "  3                  -1  1     65890  model_classes_v11_modified.CBAM              [256]                         \n",
            "  4                  -1  1    590336  model_classes_v11.Conv                       [256, 256, 3, 2]              \n",
            "  5                  -1  2    691712  model_classes_v11.C3k2                       [256, 512, 2, True, 0.25]     \n",
            "  6                  -1  1   3380736  model_classes_v11_modified.MobileViTBlock    [512, 2]                      \n",
            "  7                  -1  1   2360320  model_classes_v11.Conv                       [512, 512, 3, 2]              \n",
            "  8                  -1  2   2234368  model_classes_v11.C3k2                       [512, 512, 2, True]           \n",
            "  9                  -1  1   2360320  model_classes_v11.Conv                       [512, 512, 3, 2]              \n",
            " 10                  -1  2   2234368  model_classes_v11.C3k2                       [512, 512, 2, True]           \n",
            " 11                  -1  1    656896  model_classes.SPPF                           [512, 512, 5]                 \n",
            " 12                  -1  1   2885888  model_classes_v11_modified.ASPP_Lite         [512]                         \n",
            " 13                  -1  2   1455616  model_classes_v11.C2PSA                      [512, 512, 2]                 \n",
            " 14                  -1  1    262754  model_classes_v11_modified.CBAM              [512]                         \n",
            " 15                  -1  1         0  model_classes.Upsample                       [2, 'nearest']                \n",
            " 16             [-1, 8]  1         0  model_classes.Concat                         [1]                           \n",
            " 17                  -1  2   2496512  model_classes_v11.C3k2                       [1024, 512, 2, True]          \n",
            " 18                  -1  1         0  model_classes.Upsample                       [2, 'nearest']                \n",
            " 19             [-1, 6]  1         0  model_classes.Concat                         [1]                           \n",
            " 20                  -1  2    756736  model_classes_v11.C3k2                       [1024, 256, 2, True]          \n",
            " 21                  -1  1    590336  model_classes_v11.Conv                       [256, 256, 3, 2]              \n",
            " 22            [-1, 15]  1         0  model_classes.Concat                         [1]                           \n",
            " 23                  -1  2   2365440  model_classes_v11.C3k2                       [768, 512, 2, True]           \n",
            " 24                  -1  1   2360320  model_classes_v11.Conv                       [512, 512, 3, 2]              \n",
            " 25            [-1, 12]  1         0  model_classes.Concat                         [1]                           \n",
            " 26                  -1  2   2496512  model_classes_v11.C3k2                       [1024, 512, 2, True]          \n",
            " 27        [16, 19, 22]  1  14483986  ultralytics.nn.modules.head.Detect           [22, [1024, 1024, 768]]       \n",
            "my_YOLOv11l_back_modified summary: 422 layers, 44,978,710 parameters, 44,978,694 gradients, 219.4 GFLOPs\n",
            "\n",
            "Freezing layer 'model.27.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.40.1 ms, read: 57.010.4 MB/s, size: 70.6 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Project_1\\Dataset\\Test_dataset\\train\\labels.cache... 604 images, 9 backgrounds, 0 corrupt: 100%|██████████| 604/604 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.40.1 ms, read: 51.922.5 MB/s, size: 56.0 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "c:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Project_1\\Dataset\\Test_dataset\\valid\\labels.cache... 58 images, 1 backgrounds, 0 corrupt: 100%|██████████| 58/58 [00:00<?, ?it/s]\n",
            "c:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Ultralytics_work\\ultralytics\\runs\\detect\\train2\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 182 weight(decay=0.0), 198 weight(decay=0.0005), 198 bias(decay=0.0)\n",
            "Image sizes 64 train, 64 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mC:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Ultralytics_work\\ultralytics\\runs\\detect\\train2\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/1         0G       6.58      5.323      4.204         68         64:  18%|█▊        | 7/38 [00:24<01:46,  3.43s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mKIIT\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mVedant_Official\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mvedant projects and works\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mML_Deep_learning_projects\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDeep_Learning_Projects\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mProject_1\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDataset\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mTest_dataset\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:799\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 799\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
            "File \u001b[1;32mc:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:227\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    224\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:415\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    411\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items\n\u001b[0;32m    412\u001b[0m     )\n\u001b[0;32m    414\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 415\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n",
            "File \u001b[1;32mc:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\KIIT\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "results = model.train(data=r\"C:\\Users\\KIIT\\OneDrive\\Desktop\\Vedant_Official\\vedant projects and works\\ML_Deep_learning_projects\\Deep_Learning_Projects\\Project_1\\Dataset\\Test_dataset\\data.yaml\", epochs=1, imgsz=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNwBXzbqE-m3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
