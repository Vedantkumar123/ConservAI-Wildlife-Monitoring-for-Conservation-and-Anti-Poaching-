{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkXHdJidlpPs",
        "outputId": "d043af80-eaeb-4194-cb69-c5968a4ed368"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics -q\n",
        "!pip install roboflow -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v9yvh89MdBS",
        "outputId": "22598810-5b29-45e0-ddb4-4d7251a6ed66"
      },
      "outputs": [],
      "source": [
        "from ultralytics.nn.modules import (\n",
        "    AIFI,\n",
        "    C1,\n",
        "    C2,\n",
        "    C2PSA,\n",
        "    C3,\n",
        "    C3TR,\n",
        "    ELAN1,\n",
        "    OBB,\n",
        "    PSA,\n",
        "    SPP,\n",
        "    SPPELAN,\n",
        "    SPPF,\n",
        "    A2C2f,\n",
        "    AConv,\n",
        "    ADown,\n",
        "    Bottleneck,\n",
        "    BottleneckCSP,\n",
        "    C2f,\n",
        "    C2fAttn,\n",
        "    C2fCIB,\n",
        "    C2fPSA,\n",
        "    C3Ghost,\n",
        "    C3k2,\n",
        "    C3x,\n",
        "    CBFuse,\n",
        "    CBLinear,\n",
        "    Classify,\n",
        "    Concat,\n",
        "    Conv,\n",
        "    Conv2,\n",
        "    ConvTranspose,\n",
        "    Detect,\n",
        "    DWConv,\n",
        "    DWConvTranspose2d,\n",
        "    Focus,\n",
        "    GhostBottleneck,\n",
        "    GhostConv,\n",
        "    HGBlock,\n",
        "    HGStem,\n",
        "    ImagePoolingAttn,\n",
        "    Index,\n",
        "    LRPCHead,\n",
        "    Pose,\n",
        "    RepC3,\n",
        "    RepConv,\n",
        "    RepNCSPELAN4,\n",
        "    RepVGGDW,\n",
        "    ResNetLayer,\n",
        "    RTDETRDecoder,\n",
        "    SCDown,\n",
        "    Segment,\n",
        "    TorchVision,\n",
        "    WorldDetect,\n",
        "    YOLOEDetect,\n",
        "    YOLOESegment,\n",
        "    v10Detect,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'roboflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m config \u001b[38;5;241m=\u001b[39m configparser\u001b[38;5;241m.\u001b[39mConfigParser()\n\u001b[0;32m      3\u001b[0m config\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../myconfig.config\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroboflow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu8Ur5ywKLswqwt0uMTXl\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\configparser.py:978\u001b[0m, in \u001b[0;36mRawConfigParser.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_section \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_section(key):\n\u001b[1;32m--> 978\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proxies[key]\n",
            "\u001b[1;31mKeyError\u001b[0m: 'roboflow'"
          ]
        }
      ],
      "source": [
        "import configparser\n",
        "config = configparser.ConfigParser()\n",
        "config.read('../../myconfig.config')\n",
        "print(config['roboflow']['roboflow_api_key'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQwNxIhP_EFx",
        "outputId": "1996b950-7332-4dbd-f06b-cd3ef52fa68f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics==8.0.196 is required but found version=8.3.166, to fix: `pip install ultralytics==8.0.196`\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in poacher-2 to yolov8:: 100%|██████████| 44579/44579 [00:23<00:00, 1862.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to poacher-2 in yolov8:: 100%|██████████| 1396/1396 [00:00<00:00, 2020.27it/s]\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key='u8Ur5ywKLswqwt0uMTXl')\n",
        "project = rf.workspace(\"poacher-ifyuf\").project(\"poacher\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bOcaZ6dnMDR"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/drive/MyDrive/Colab_Notebooks/YOLO_architecture/utillity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "go1t4uz6uARV"
      },
      "outputs": [],
      "source": [
        "from ultralytics import nn\n",
        "from ultralytics.nn import modules, tasks\n",
        "import ultralytics.nn.autobackend as autobackend\n",
        "from model_classes import Upsample, Conv, C2f, SPPF, DFL, Head, Bottleneck, Concat\n",
        "from ultralytics.nn.tasks import parse_model, yaml_model_load\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "def patch_ultralytics_layers(custom_classes):\n",
        "    submodules = [\n",
        "        nn,                          # ultralytics.nn\n",
        "        modules,                     # ultralytics.nn.modules\n",
        "        tasks,                       # ultralytics.nn.tasks\n",
        "        autobackend,                 # ultralytics.nn.autobackend\n",
        "    ]\n",
        "\n",
        "    for cls in custom_classes:\n",
        "        for mod in submodules:\n",
        "            mod.__dict__[cls.__name__] = cls\n",
        "\n",
        "def build_model(model_yaml, version='n', ch=3, verbose=False, custom_classes=[]):\n",
        "\n",
        "  patch_ultralytics_layers(custom_classes)\n",
        "\n",
        "  mod_ya = model_yaml if isinstance(model_yaml, dict) else yaml_model_load(model_yaml)\n",
        "  mod_ya['scale'] = version.lower()\n",
        "  model, save  = parse_model(deepcopy(mod_ya), ch=ch, verbose=verbose)\n",
        "\n",
        "  return model,save\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg1Fe3WHzfZJ",
        "outputId": "d9ddbd32-916b-4438-c8ff-ee7337ac837d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  model_classes.Conv                           [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  model_classes.Conv                           [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  model_classes.C2f                            [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  model_classes.Conv                           [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  model_classes.C2f                            [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  model_classes.Conv                           [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  model_classes.C2f                            [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  model_classes.Conv                           [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  model_classes.C2f                            [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  model_classes.SPPF                           [512, 512, 5]                 \n",
            " 10                  -1  1         0  model_classes.Upsample                       [2, 'nearest']                \n",
            " 11             [-1, 6]  1         0  model_classes.Concat                         [1]                           \n",
            " 12                  -1  3   4723712  model_classes.C2f                            [1024, 512, 3]                \n",
            " 13                  -1  1         0  model_classes.Upsample                       [2, 'nearest']                \n",
            " 14             [-1, 4]  1         0  model_classes.Concat                         [1]                           \n",
            " 15                  -1  3   1247744  model_classes.C2f                            [768, 256, 3]                 \n",
            " 16                  -1  1    590336  model_classes.Conv                           [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  model_classes.Concat                         [1]                           \n",
            " 18                  -1  3   4592640  model_classes.C2f                            [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  model_classes.Conv                           [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  model_classes.Concat                         [1]                           \n",
            " 21                  -1  3   4723712  model_classes.C2f                            [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5644480  ultralytics.nn.modules.head.Detect           [80, [256, 512, 512]]         \n",
            "my_YOLOv8l summary: 294 layers, 43,691,520 parameters, 43,691,504 gradients, 165.7 GFLOPs\n",
            "\n",
            "43.69 million parameters\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "m_class = [Upsample, Conv, C2f, SPPF, DFL, Head, Bottleneck, Concat]\n",
        "model_yaml = \"my_yolov8l.yaml\"\n",
        "\n",
        "model,save = build_model(model_yaml, custom_classes=m_class, version='l', verbose=False)\n",
        "\n",
        "model = YOLO(model_yaml, verbose=True)\n",
        "print(f\"{sum(p.numel() for p in model.parameters()) / 1e6:.2f} million parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gaRK0qtTMI3r",
        "outputId": "89eacea5-f74a-49c6-e47d-c6e24f20e609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
          ]
        }
      ],
      "source": [
        "for m in model.modules():\n",
        "  if isinstance(m, (Conv, Conv2, DWConv)) and hasattr(m, \"bn\"):\n",
        "    if isinstance(m, Conv2):\n",
        "      pass\n",
        "    print(m.conv)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSsalGpq-_ly",
        "outputId": "63d0b951-9c16-46b6-91dc-1f563421d2a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.189 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.166  Python-3.11.1 torch-2.4.1+cpu CPU (11th Gen Intel Core(TM) i5-11400H 2.70GHz)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=D:\\WORK\\project 1\\Architecture\\Test_Dataset\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=64, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=my_yolov8l.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=train4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=22\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  model_classes.Conv                           [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  model_classes.Conv                           [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  model_classes.C2f                            [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  model_classes.Conv                           [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  model_classes.C2f                            [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  model_classes.Conv                           [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  model_classes.C2f                            [512, 512, 6, True]           \n",
            "  7                  -1  1   2360320  model_classes.Conv                           [512, 512, 3, 2]              \n",
            "  8                  -1  3   4461568  model_classes.C2f                            [512, 512, 3, True]           \n",
            "  9                  -1  1    656896  model_classes.SPPF                           [512, 512, 5]                 \n",
            " 10                  -1  1         0  model_classes.Upsample                       [2, 'nearest']                \n",
            " 11             [-1, 6]  1         0  model_classes.Concat                         [1]                           \n",
            " 12                  -1  3   4723712  model_classes.C2f                            [1024, 512, 3]                \n",
            " 13                  -1  1         0  model_classes.Upsample                       [2, 'nearest']                \n",
            " 14             [-1, 4]  1         0  model_classes.Concat                         [1]                           \n",
            " 15                  -1  3   1247744  model_classes.C2f                            [768, 256, 3]                 \n",
            " 16                  -1  1    590336  model_classes.Conv                           [256, 256, 3, 2]              \n",
            " 17            [-1, 12]  1         0  model_classes.Concat                         [1]                           \n",
            " 18                  -1  3   4592640  model_classes.C2f                            [768, 512, 3]                 \n",
            " 19                  -1  1   2360320  model_classes.Conv                           [512, 512, 3, 2]              \n",
            " 20             [-1, 9]  1         0  model_classes.Concat                         [1]                           \n",
            " 21                  -1  3   4723712  model_classes.C2f                            [1024, 512, 3]                \n",
            " 22        [15, 18, 21]  1   5599762  ultralytics.nn.modules.head.Detect           [22, [256, 512, 512]]         \n",
            "my_YOLOv8l summary: 294 layers, 43,646,802 parameters, 43,646,786 gradients, 165.5 GFLOPs\n",
            "\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 5.50.4 MB/s, size: 70.6 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\WORK\\project 1\\Architecture\\Test_Dataset\\train\\labels... 604 images, 9 backgrounds, 0 corrupt: 100%|██████████| 604/604 [00:02<00:00, 242.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\WORK\\project 1\\Architecture\\Test_Dataset\\train\\labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.3 ms, read: 5.92.3 MB/s, size: 56.0 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\WORK\\project 1\\Architecture\\Test_Dataset\\valid\\labels... 58 images, 1 backgrounds, 0 corrupt: 100%|██████████| 58/58 [00:00<00:00, 254.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\WORK\\project 1\\Architecture\\Test_Dataset\\valid\\labels.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs\\detect\\train4\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000385, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
            "Image sizes 64 train, 64 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns\\detect\\train4\u001b[0m\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "        1/1         0G      6.446      5.152      4.015         48         64: 100%|██████████| 38/38 [00:37<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:02<00:00,  1.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         58        122          0          0          0          0\n",
            "\n",
            "1 epochs completed in 0.012 hours.\n",
            "Optimizer stripped from runs\\detect\\train4\\weights\\last.pt, 87.6MB\n",
            "Optimizer stripped from runs\\detect\\train4\\weights\\best.pt, 87.6MB\n",
            "\n",
            "Validating runs\\detect\\train4\\weights\\best.pt...\n",
            "Ultralytics 8.3.166  Python-3.11.1 torch-2.4.1+cpu CPU (11th Gen Intel Core(TM) i5-11400H 2.70GHz)\n",
            "my_YOLOv8l summary: 209 layers, 43,625,490 parameters, 0 gradients, 164.9 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         58        122          0          0          0          0\n",
            "                animal          2          2          0          0          0          0\n",
            "                  bull          1          1          0          0          0          0\n",
            "                 camel          2          4          0          0          0          0\n",
            "                  deer          3          3          0          0          0          0\n",
            "                   dog          2          3          0          0          0          0\n",
            "              elephant          8          8          0          0          0          0\n",
            "                   fox          1          1          0          0          0          0\n",
            "                  lion          2          2          0          0          0          0\n",
            "               poacher         18         29          0          0          0          0\n",
            "                ranger         18         32          0          0          0          0\n",
            "                 rhino          5          6          0          0          0          0\n",
            "                 tiger          1          1          0          0          0          0\n",
            "                weapon         24         30          0          0          0          0\n",
            "Speed: 0.0ms preprocess, 19.6ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
            "Results saved to \u001b[1mruns\\detect\\train4\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "results = model.train(data=r\"D:\\WORK\\project 1\\Architecture\\Test_Dataset\\data.yaml\", epochs=1, imgsz=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FNwBXzbqE-m3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
